INFO: [v++ 60-1306] Additional information associated with this v++ link can be found at:
	Reports: /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/reports/link
	Log files: /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/logs/link
INFO: [v++ 60-1548] Creating build summary session with primary output /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/build_dir_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/krnl_vaddmul.link.xclbin.link_summary, at Mon Oct 21 06:43:19 2024
INFO: [v++ 60-1316] Initiating connection to rulecheck server, at Mon Oct 21 06:43:19 2024
INFO: [v++ 60-1315] Creating rulecheck session with output '/home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/reports/link/v++_link_krnl_vaddmul.link_guidance.html', at Mon Oct 21 06:43:21 2024
INFO: [v++ 60-895]   Target platform: /opt/xilinx/platforms/xilinx_u280_xdma_201920_3/xilinx_u280_xdma_201920_3.xpfm
INFO: [v++ 60-1578]   This platform contains Xilinx Shell Archive '/opt/xilinx/platforms/xilinx_u280_xdma_201920_3/hw/xilinx_u280_xdma_201920_3.xsa'
INFO: [v++ 74-78] Compiler Version string: 2021.2
INFO: [v++ 60-1302] Platform 'xilinx_u280_xdma_201920_3.xpfm' has been explicitly enabled for this release.
INFO: [v++ 60-629] Linking for hardware target
INFO: [v++ 60-423]   Target device: xilinx_u280_xdma_201920_3
INFO: [v++ 60-1332] Run 'run_link' status: Not started
INFO: [v++ 60-1443] [06:43:36] Run run_link: Step system_link: Started
INFO: [v++ 60-1453] Command Line: system_link --xo /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/krnl_vaddmul.xo -keep --config /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/syslinkConfig.ini --xpfm /opt/xilinx/platforms/xilinx_u280_xdma_201920_3/xilinx_u280_xdma_201920_3.xpfm --target hw --output_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int --temp_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link
INFO: [v++ 60-1454] Run Directory: /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/run_link
INFO: [SYSTEM_LINK 60-1316] Initiating connection to rulecheck server, at Mon Oct 21 06:43:39 2024
INFO: [SYSTEM_LINK 82-70] Extracting xo v3 file /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/krnl_vaddmul.xo
INFO: [SYSTEM_LINK 82-53] Creating IP database /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/_sysl/.cdb/xd_ip_db.xml
INFO: [SYSTEM_LINK 82-38] [06:43:49] build_xd_ip_db started: /tools/Xilinx/Vitis/2021.2/bin/build_xd_ip_db -ip_search 0  -sds-pf /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/xilinx_u280_xdma_201920_3.hpfm -clkid 0 -ip /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/iprepo/xilinx_com_hls_krnl_vaddmul_1_0,krnl_vaddmul -o /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/_sysl/.cdb/xd_ip_db.xml
INFO: [SYSTEM_LINK 82-37] [06:43:56] build_xd_ip_db finished successfully
Time (s): cpu = 00:00:04 ; elapsed = 00:00:07 . Memory (MB): peak = 2167.246 ; gain = 0.000 ; free physical = 213164 ; free virtual = 505157
INFO: [SYSTEM_LINK 82-51] Create system connectivity graph
INFO: [SYSTEM_LINK 82-102] Applying explicit connections to the system connectivity graph: /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/cfgraph/cfgen_cfgraph.xml
INFO: [SYSTEM_LINK 82-38] [06:43:56] cfgen started: /tools/Xilinx/Vitis/2021.2/bin/cfgen  -nk krnl_vaddmul:8 -sp krnl_vaddmul_1.in1:HBM[0] -sp krnl_vaddmul_1.in2:HBM[1] -sp krnl_vaddmul_1.out_add:HBM[2] -sp krnl_vaddmul_1.out_mul:HBM[3] -sp krnl_vaddmul_2.in1:HBM[4] -sp krnl_vaddmul_2.in2:HBM[5] -sp krnl_vaddmul_2.out_add:HBM[6] -sp krnl_vaddmul_2.out_mul:HBM[7] -sp krnl_vaddmul_3.in1:HBM[8] -sp krnl_vaddmul_3.in2:HBM[9] -sp krnl_vaddmul_3.out_add:HBM[10] -sp krnl_vaddmul_3.out_mul:HBM[11] -sp krnl_vaddmul_4.in1:HBM[12] -sp krnl_vaddmul_4.in2:HBM[13] -sp krnl_vaddmul_4.out_add:HBM[14] -sp krnl_vaddmul_4.out_mul:HBM[15] -sp krnl_vaddmul_5.in1:HBM[16] -sp krnl_vaddmul_5.in2:HBM[17] -sp krnl_vaddmul_5.out_add:HBM[18] -sp krnl_vaddmul_5.out_mul:HBM[19] -sp krnl_vaddmul_6.in1:HBM[20] -sp krnl_vaddmul_6.in2:HBM[21] -sp krnl_vaddmul_6.out_add:HBM[22] -sp krnl_vaddmul_6.out_mul:HBM[23] -sp krnl_vaddmul_7.in1:HBM[24] -sp krnl_vaddmul_7.in2:HBM[25] -sp krnl_vaddmul_7.out_add:HBM[26] -sp krnl_vaddmul_7.out_mul:HBM[27] -sp krnl_vaddmul_8.in1:HBM[28] -sp krnl_vaddmul_8.in2:HBM[29] -sp krnl_vaddmul_8.out_add:HBM[30] -sp krnl_vaddmul_8.out_mul:HBM[31] -dmclkid 0 -r /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/_sysl/.cdb/xd_ip_db.xml -o /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/cfgraph/cfgen_cfgraph.xml
INFO: [CFGEN 83-0] Kernel Specs: 
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul, num: 8  {krnl_vaddmul_1 krnl_vaddmul_2 krnl_vaddmul_3 krnl_vaddmul_4 krnl_vaddmul_5 krnl_vaddmul_6 krnl_vaddmul_7 krnl_vaddmul_8}
INFO: [CFGEN 83-0] Port Specs: 
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_1, k_port: in1, sptag: HBM[0]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_1, k_port: in2, sptag: HBM[1]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_1, k_port: out_add, sptag: HBM[2]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_1, k_port: out_mul, sptag: HBM[3]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_2, k_port: in1, sptag: HBM[4]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_2, k_port: in2, sptag: HBM[5]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_2, k_port: out_add, sptag: HBM[6]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_2, k_port: out_mul, sptag: HBM[7]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_3, k_port: in1, sptag: HBM[8]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_3, k_port: in2, sptag: HBM[9]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_3, k_port: out_add, sptag: HBM[10]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_3, k_port: out_mul, sptag: HBM[11]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_4, k_port: in1, sptag: HBM[12]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_4, k_port: in2, sptag: HBM[13]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_4, k_port: out_add, sptag: HBM[14]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_4, k_port: out_mul, sptag: HBM[15]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_5, k_port: in1, sptag: HBM[16]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_5, k_port: in2, sptag: HBM[17]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_5, k_port: out_add, sptag: HBM[18]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_5, k_port: out_mul, sptag: HBM[19]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_6, k_port: in1, sptag: HBM[20]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_6, k_port: in2, sptag: HBM[21]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_6, k_port: out_add, sptag: HBM[22]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_6, k_port: out_mul, sptag: HBM[23]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_7, k_port: in1, sptag: HBM[24]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_7, k_port: in2, sptag: HBM[25]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_7, k_port: out_add, sptag: HBM[26]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_7, k_port: out_mul, sptag: HBM[27]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_8, k_port: in1, sptag: HBM[28]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_8, k_port: in2, sptag: HBM[29]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_8, k_port: out_add, sptag: HBM[30]
INFO: [CFGEN 83-0]   kernel: krnl_vaddmul_8, k_port: out_mul, sptag: HBM[31]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_1.in1 to HBM[0] for directive krnl_vaddmul_1.in1:HBM[0]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_1.in2 to HBM[1] for directive krnl_vaddmul_1.in2:HBM[1]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_1.out_add to HBM[2] for directive krnl_vaddmul_1.out_add:HBM[2]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_1.out_mul to HBM[3] for directive krnl_vaddmul_1.out_mul:HBM[3]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_2.in1 to HBM[4] for directive krnl_vaddmul_2.in1:HBM[4]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_2.in2 to HBM[5] for directive krnl_vaddmul_2.in2:HBM[5]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_2.out_add to HBM[6] for directive krnl_vaddmul_2.out_add:HBM[6]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_2.out_mul to HBM[7] for directive krnl_vaddmul_2.out_mul:HBM[7]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_3.in1 to HBM[8] for directive krnl_vaddmul_3.in1:HBM[8]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_3.in2 to HBM[9] for directive krnl_vaddmul_3.in2:HBM[9]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_3.out_add to HBM[10] for directive krnl_vaddmul_3.out_add:HBM[10]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_3.out_mul to HBM[11] for directive krnl_vaddmul_3.out_mul:HBM[11]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_4.in1 to HBM[12] for directive krnl_vaddmul_4.in1:HBM[12]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_4.in2 to HBM[13] for directive krnl_vaddmul_4.in2:HBM[13]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_4.out_add to HBM[14] for directive krnl_vaddmul_4.out_add:HBM[14]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_4.out_mul to HBM[15] for directive krnl_vaddmul_4.out_mul:HBM[15]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_5.in1 to HBM[16] for directive krnl_vaddmul_5.in1:HBM[16]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_5.in2 to HBM[17] for directive krnl_vaddmul_5.in2:HBM[17]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_5.out_add to HBM[18] for directive krnl_vaddmul_5.out_add:HBM[18]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_5.out_mul to HBM[19] for directive krnl_vaddmul_5.out_mul:HBM[19]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_6.in1 to HBM[20] for directive krnl_vaddmul_6.in1:HBM[20]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_6.in2 to HBM[21] for directive krnl_vaddmul_6.in2:HBM[21]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_6.out_add to HBM[22] for directive krnl_vaddmul_6.out_add:HBM[22]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_6.out_mul to HBM[23] for directive krnl_vaddmul_6.out_mul:HBM[23]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_7.in1 to HBM[24] for directive krnl_vaddmul_7.in1:HBM[24]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_7.in2 to HBM[25] for directive krnl_vaddmul_7.in2:HBM[25]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_7.out_add to HBM[26] for directive krnl_vaddmul_7.out_add:HBM[26]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_7.out_mul to HBM[27] for directive krnl_vaddmul_7.out_mul:HBM[27]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_8.in1 to HBM[28] for directive krnl_vaddmul_8.in1:HBM[28]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_8.in2 to HBM[29] for directive krnl_vaddmul_8.in2:HBM[29]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_8.out_add to HBM[30] for directive krnl_vaddmul_8.out_add:HBM[30]
INFO: [CFGEN 83-2228] Creating mapping for argument krnl_vaddmul_8.out_mul to HBM[31] for directive krnl_vaddmul_8.out_mul:HBM[31]
INFO: [SYSTEM_LINK 82-37] [06:44:04] cfgen finished successfully
Time (s): cpu = 00:00:07 ; elapsed = 00:00:08 . Memory (MB): peak = 2167.246 ; gain = 0.000 ; free physical = 213168 ; free virtual = 505161
INFO: [SYSTEM_LINK 82-52] Create top-level block diagram
INFO: [SYSTEM_LINK 82-38] [06:44:04] cf2bd started: /tools/Xilinx/Vitis/2021.2/bin/cf2bd  --linux --trace_buffer 1024 --input_file /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/cfgraph/cfgen_cfgraph.xml --ip_db /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/_sysl/.cdb/xd_ip_db.xml --cf_name dr --working_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/_sysl/.xsd --temp_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link --output_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int --target_bd pfm_dynamic.bd
INFO: [CF2BD 82-31] Launching cf2xd: cf2xd -linux -trace-buffer 1024 -i /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/cfgraph/cfgen_cfgraph.xml -r /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/_sysl/.cdb/xd_ip_db.xml -o dr.xml
INFO: [CF2BD 82-28] cf2xd finished successfully
INFO: [CF2BD 82-31] Launching cf_xsd: cf_xsd -disable-address-gen -bd pfm_dynamic.bd -dn dr -dp /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/sys_link/_sysl/.xsd
INFO: [CF2BD 82-28] cf_xsd finished successfully
INFO: [SYSTEM_LINK 82-37] [06:44:11] cf2bd finished successfully
Time (s): cpu = 00:00:06 ; elapsed = 00:00:07 . Memory (MB): peak = 2167.246 ; gain = 0.000 ; free physical = 213160 ; free virtual = 505158
INFO: [v++ 60-1441] [06:44:11] Run run_link: Step system_link: Completed
Time (s): cpu = 00:00:21 ; elapsed = 00:00:35 . Memory (MB): peak = 2062.203 ; gain = 0.000 ; free physical = 213204 ; free virtual = 505203
INFO: [v++ 60-1443] [06:44:11] Run run_link: Step cf2sw: Started
INFO: [v++ 60-1453] Command Line: cf2sw -sdsl /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/sdsl.dat -rtd /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/cf2sw.rtd -nofilter /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/cf2sw_full.rtd -xclbin /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/xclbin_orig.xml -o /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/xclbin_orig.1.xml
INFO: [v++ 60-1454] Run Directory: /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/run_link
INFO: [v++ 60-1441] [06:44:20] Run run_link: Step cf2sw: Completed
Time (s): cpu = 00:00:08 ; elapsed = 00:00:09 . Memory (MB): peak = 2062.203 ; gain = 0.000 ; free physical = 213206 ; free virtual = 505204
INFO: [v++ 60-1443] [06:44:20] Run run_link: Step rtd2_system_diagram: Started
INFO: [v++ 60-1453] Command Line: rtd2SystemDiagram
INFO: [v++ 60-1454] Run Directory: /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/run_link
INFO: [v++ 60-1441] [06:44:20] Run run_link: Step rtd2_system_diagram: Completed
Time (s): cpu = 00:00:00 ; elapsed = 00:00:00.69 . Memory (MB): peak = 2062.203 ; gain = 0.000 ; free physical = 213197 ; free virtual = 505196
INFO: [v++ 60-1443] [06:44:20] Run run_link: Step vpl: Started
INFO: [v++ 60-1453] Command Line: vpl -t hw -f xilinx_u280_xdma_201920_3 --remote_ip_cache /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/.ipcache -s --output_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int --log_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/logs/link --report_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/reports/link --config /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/vplConfig.ini -k /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/kernel_info.dat --webtalk_flag Vitis --temp_dir /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link --no-info --iprepo /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/xo/ip_repo/xilinx_com_hls_krnl_vaddmul_1_0 --messageDb /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/run_link/vpl.pb /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/dr.bd.tcl
INFO: [v++ 60-1454] Run Directory: /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/run_link

****** vpl v2021.2 (64-bit)
  **** SW Build 3363252 on 2021-10-14-04:41:01
    ** Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.

INFO: [VPL 60-839] Read in kernel information from file '/home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/int/kernel_info.dat'.
INFO: [VPL 74-78] Compiler Version string: 2021.2
INFO: [VPL 60-423]   Target device: xilinx_u280_xdma_201920_3
INFO: [VPL 60-1032] Extracting hardware platform to /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/vivado/vpl/.local/hw_platform
[06:52:39] Run vpl: Step create_project: Started
Creating Vivado project.
[06:52:54] Run vpl: Step create_project: Completed
[06:52:54] Run vpl: Step create_bd: Started
[06:54:15] Run vpl: Step create_bd: RUNNING...
[06:55:32] Run vpl: Step create_bd: RUNNING...
[06:56:50] Run vpl: Step create_bd: RUNNING...
[06:58:08] Run vpl: Step create_bd: RUNNING...
[06:59:26] Run vpl: Step create_bd: RUNNING...
[07:00:45] Run vpl: Step create_bd: RUNNING...
[07:02:01] Run vpl: Step create_bd: RUNNING...
[07:03:19] Run vpl: Step create_bd: RUNNING...
[07:03:47] Run vpl: Step create_bd: Completed
[07:03:47] Run vpl: Step update_bd: Started
[07:03:51] Run vpl: Step update_bd: Completed
[07:03:51] Run vpl: Step generate_target: Started
[07:05:08] Run vpl: Step generate_target: RUNNING...
[07:06:26] Run vpl: Step generate_target: RUNNING...
[07:07:43] Run vpl: Step generate_target: RUNNING...
[07:09:01] Run vpl: Step generate_target: RUNNING...
[07:10:19] Run vpl: Step generate_target: RUNNING...
[07:11:39] Run vpl: Step generate_target: RUNNING...
[07:12:57] Run vpl: Step generate_target: RUNNING...
[07:14:17] Run vpl: Step generate_target: RUNNING...
[07:14:58] Run vpl: Step generate_target: Completed
[07:14:58] Run vpl: Step config_hw_runs: Started
[07:15:19] Run vpl: Step config_hw_runs: Completed
[07:15:19] Run vpl: Step synth: Started
[07:15:52] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:16:25] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:16:57] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:17:28] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:18:00] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:18:32] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:19:04] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:19:35] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:20:07] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:20:38] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:21:10] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:21:42] Block-level synthesis in progress, 0 of 8 jobs complete, 1 job running.
[07:22:14] Block-level synthesis in progress, 1 of 8 jobs complete, 0 jobs running.
[07:22:49] Block-level synthesis in progress, 2 of 8 jobs complete, 6 jobs running.
[07:23:22] Top-level synthesis in progress.
[07:23:53] Top-level synthesis in progress.
[07:24:25] Top-level synthesis in progress.
[07:24:57] Top-level synthesis in progress.
[07:25:29] Top-level synthesis in progress.
[07:25:46] Run vpl: Step synth: Completed
[07:25:46] Run vpl: Step impl: Started
[07:43:49] Finished 2nd of 6 tasks (FPGA linking synthesized kernels to platform). Elapsed time: 00h 59m 26s 

[07:43:49] Starting logic optimization..
[07:47:00] Phase 1 Retarget
[07:47:33] Phase 2 Constant propagation
[07:48:04] Phase 3 Sweep
[07:51:16] Phase 4 BUFG optimization
[07:51:48] Phase 5 Shift Register Optimization
[07:51:48] Phase 6 Post Processing Netlist
[07:56:03] Finished 3rd of 6 tasks (FPGA logic optimization). Elapsed time: 00h 12m 14s 

[07:56:03] Starting logic placement..
[07:57:39] Phase 1 Placer Initialization
[07:57:39] Phase 1.1 Placer Initialization Netlist Sorting
[08:02:26] Phase 1.2 IO Placement/ Clock Placement/ Build Placer Device
[08:04:34] Phase 1.3 Build Placer Netlist Model
[08:08:49] Phase 1.4 Constrain Clocks/Macros
[08:09:20] Phase 2 Global Placement
[08:09:20] Phase 2.1 Floorplanning
[08:10:56] Phase 2.1.1 Partition Driven Placement
[08:10:56] Phase 2.1.1.1 PBP: Partition Driven Placement
[08:14:40] Phase 2.1.1.2 PBP: Clock Region Placement
[08:16:17] Phase 2.1.1.3 PBP: Discrete Incremental
[08:16:17] Phase 2.1.1.4 PBP: Compute Congestion
[08:16:17] Phase 2.1.1.5 PBP: Macro Placement
[08:16:49] Phase 2.1.1.6 PBP: UpdateTiming
[08:17:21] Phase 2.1.1.7 PBP: Add part constraints
[08:17:21] Phase 2.2 Physical Synthesis After Floorplan
[08:18:58] Phase 2.3 Update Timing before SLR Path Opt
[08:18:58] Phase 2.4 Post-Processing in Floorplanning
[08:18:58] Phase 2.5 Global Placement Core
[08:36:08] Phase 2.5.1 Physical Synthesis In Placer
[08:45:14] Phase 3 Detail Placement
[08:45:14] Phase 3.1 Commit Multi Column Macros
[08:45:14] Phase 3.2 Commit Most Macros & LUTRAMs
[08:48:59] Phase 3.3 Small Shape DP
[08:48:59] Phase 3.3.1 Small Shape Clustering
[08:49:32] Phase 3.3.2 Flow Legalize Slice Clusters
[08:49:32] Phase 3.3.3 Slice Area Swap
[08:52:45] Phase 3.4 Place Remaining
[08:52:45] Phase 3.5 Re-assign LUT pins
[08:53:49] Phase 3.6 Pipeline Register Optimization
[08:53:50] Phase 3.7 Fast Optimization
[08:57:04] Phase 4 Post Placement Optimization and Clean-Up
[08:57:04] Phase 4.1 Post Commit Optimization
[09:00:50] Phase 4.1.1 Post Placement Optimization
[09:01:22] Phase 4.1.1.1 BUFG Insertion
[09:01:22] Phase 1 Physical Synthesis Initialization
[09:05:40] Phase 4.1.1.2 BUFG Replication
[09:05:40] Phase 4.1.1.3 Post Placement Timing Optimization
[09:13:41] Phase 4.1.1.4 Replication
[09:17:26] Phase 4.2 Post Placement Cleanup
[09:17:26] Phase 4.3 Placer Reporting
[09:17:26] Phase 4.3.1 Print Estimated Congestion
[09:17:26] Phase 4.4 Final Placement Cleanup
[09:36:15] Finished 4th of 6 tasks (FPGA logic placement). Elapsed time: 01h 40m 11s 

[09:36:15] Starting logic routing..
[09:37:51] Phase 1 Build RT Design
[09:42:44] Phase 2 Router Initialization
[09:42:44] Phase 2.1 Fix Topology Constraints
[09:43:17] Phase 2.2 Pre Route Cleanup
[09:43:48] Phase 2.3 Global Clock Net Routing
[09:44:21] Phase 2.4 Update Timing
[09:50:47] Phase 2.5 Update Timing for Bus Skew
[09:50:47] Phase 2.5.1 Update Timing
[09:54:00] Phase 3 Initial Routing
[09:54:00] Phase 3.1 Global Routing
[09:58:49] Phase 3.2 Update Timing
[10:07:39] Phase 3.3 Update Timing
[10:16:14] Phase 3.4 Update Timing
[10:24:55] Phase 3.5 Update Timing
[10:33:31] Phase 3.6 Update Timing
[10:37:49] Phase 3.7 Update Timing
[10:43:12] Phase 4 Rip-up And Reroute
[10:43:12] Phase 4.1 Global Iteration 0
[10:43:45] Phase 4.2 Global Iteration 1
[14:06:24] Phase 4.3 Global Iteration 2
[15:30:57] Phase 5 Delay and Skew Optimization
[15:30:57] Phase 5.1 Delay CleanUp
[15:30:57] Phase 5.2 Clock Skew Optimization
[15:32:01] Phase 6 Post Hold Fix
[15:32:01] Phase 6.1 Hold Fix Iter
[15:33:06] Phase 6.2 Additional Hold Fix
[15:34:12] Phase 7 Leaf Clock Prog Delay Opt
[15:36:22] Phase 8 Route finalize
[15:36:54] Phase 9 Verifying routed nets
[15:37:26] Phase 10 Depositing Routes
[15:45:34] Run vpl: Step impl: Failed
[15:45:39] Run vpl: FINISHED. Run Status: impl ERROR

===>The following messages were generated while processing /home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/vivado/vpl/prj/prj.runs/impl_1 :
ERROR: [VPL 18-1000] Routing results verification failed due to partially-conflicted nets (Up to first 10 of violated nets):  pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/fifo_rreq/mem_reg[304][36]_mux__3_n_0 pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/fifo_rreq/mem_reg[304][3]_mux__3_n_0 pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/fifo_rreq/mem_reg[304][3]_mux__5_n_0 pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/buff_rdata/if_dout[31] pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/buff_rdata/pop pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/buff_rdata/show_ahead pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/buff_rdata/waddr__0 pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/buff_rdata/if_dout[91] pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/buff_rdata/if_dout[106] pfm_top_i/dynamic_region/krnl_vaddmul_1/inst/gmem0_m_axi_U/bus_read/buff_rdata/if_dout[111] 
ERROR: [VPL 60-773] In '/home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/vivado/vpl/runme.log', caught Tcl error:  problem implementing dynamic region, impl_1: route_design ERROR, please look at the run log file '/home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/vivado/vpl/prj/prj.runs/impl_1/runme.log' for more information
WARNING: [VPL 60-732] Link warning: No monitor points found for BD automation.
ERROR: [VPL 60-704] Integration error, problem implementing dynamic region, impl_1: route_design ERROR, please look at the run log file '/home/ziyuanwang/hbm/Vitis_Accel_Examples/performance/hbm_bandwidth_pseudo_random/_x_8core_mulmul_32.hw.xilinx_u280_xdma_201920_3/link/vivado/vpl/prj/prj.runs/impl_1/runme.log' for more information
ERROR: [VPL 60-1328] Vpl run 'vpl' failed
ERROR: [VPL 60-806] Failed to finish platform linker
INFO: [v++ 60-1442] [15:46:44] Run run_link: Step vpl: Failed
Time (s): cpu = 00:05:38 ; elapsed = 09:02:23 . Memory (MB): peak = 2062.203 ; gain = 0.000 ; free physical = 209219 ; free virtual = 505107
ERROR: [v++ 60-661] v++ link run 'run_link' failed
ERROR: [v++ 60-626] Kernel link failed to complete
ERROR: [v++ 60-703] Failed to finish linking
